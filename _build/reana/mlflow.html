---
title: |-
  MLFlow
pagenum: 27
prev_page:
  url: /reana/execution.html
next_page:
  url: /reana/parametrization.html
suffix: .md
search: mlflow tracking server workflow host ml running run experiments url docker case bash create runs reana need deployed locally internal export experiment name madminer projects results metrics artifacts following sub common yadage using install file tmp connection specify just before mlflowtrackinguri here note bonus org framework offers developers consistent defining parameterized those track images mlflowscreenshot png integrated part order provide third capability consecutive different therefore explanations apply complete only leaving physics unaffected preliminary requirements remotely provided http accessible computer including laptop not dont deploy very own python package pip launch port workers backend store uri metadata default artifact root setup

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">MLFlow</div>
</div>
    
<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Bonus:-MLFlow">Bonus: MLFlow<a class="anchor-link" href="#Bonus:-MLFlow"> </a></h1><p><a href="https://mlflow.org">MLFlow</a> is a framework that offers developers a consistent way of (1) defining ML projects, (2) run parameterized experiments on those projects, and (3) track results, metrics and artifacts from run to run.</p>
<p><img src="../images/mlflow_screenshot.png" alt=""></p>
<p>In the case of this workflow, MLFlow has been <strong>integrated to the ML part of the workflow</strong>, in order to provide the third capability: the tracking of results and metrics on consecutive (but different) runs. Therefore, the following explanations apply to the ML sub-workflow, and the complete workflow only, leaving the physics sub-workflow unaffected.</p>
<h2 id="Preliminary-requirements">Preliminary requirements<a class="anchor-link" href="#Preliminary-requirements"> </a></h2><p>If you are running remotely on REANA, you will need an MLFlow tracking server up and running.</p>
<p>This could be provided to you (common case), or deployed by you in a HTTP accessible computer (including your laptop). If you are running the workflow locally with yadage (not using REANA), then you don’t need an MLflow tracking server running.</p>
<p>To deploy your very own MLFlow tracking server:</p>
<div class="highlight"><pre><span></span><span class="c1"># Install the Python package</span>
pip3 install mlflow

<span class="c1"># Launch the tracking server</span>
mlflow server <span class="se">\ </span>                                                
    --host <span class="s2">&quot;0.0.0.0&quot;</span> <span class="se">\</span>
    --port <span class="m">5000</span> <span class="se">\</span>
    --workers <span class="m">2</span> <span class="se">\</span>
    --backend-store-uri <span class="s2">&quot;file:///tmp/mlflow/runs/metadata&quot;</span> <span class="se">\</span>
    --default-artifact-root <span class="s2">&quot;file:///tmp/mlflow/runs/artifacts&quot;</span>
</pre></div>
<h2 id="Connection-setup">Connection setup<a class="anchor-link" href="#Connection-setup"> </a></h2><p>Once you have an up-and-running MLFlow tracking server, you can specify the connection URL to the workflow just before executing it. If your tracking server instance has been deployed locally, the URL needs to be: <code>http://host.docker.internal:5000</code>, otherwise, specify a common URL:</p>
<div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">MLFLOW_TRACKING_URI</span><span class="o">=</span>”&lt;the tracking server URL here&gt;”

<span class="c1"># One of the following high-level commands</span>
make yadage-run 
make reana-run
</pre></div>
<p><em>Note 1</em>: There is an additional environment variable to set up in case the MLFlow tracking server was deployed locally, and you are using Linux. This command tells Docker to map the magic string <code>host.docker.internal</code> to what Docker considers the “host network”:</p>
<div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">PACKTIVITY_DOCKER_CMD_MOD</span><span class="o">=</span><span class="s2">&quot;--add-host host.docker.internal:host-gateway&quot;</span>
</pre></div>
<p><em>Note 2</em>: due to some race conditions within the MLFlow implementation, you may need to preventively create the MLFlow tracking server experiments before running the workflow. This may have been fixed by the time you are reading this, but just in case.</p>
<div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">MLFLOW_TRACKING_URI</span><span class="o">=</span>”&lt;the tracking server URL here&gt;”

mlflow experiments create --experiment-name <span class="s2">&quot;madminer-ml-sample&quot;</span>
mlflow experiments create --experiment-name <span class="s2">&quot;madminer-ml-train&quot;</span>
mlflow experiments create --experiment-name <span class="s2">&quot;madminer-ml-eval&quot;</span>
</pre></div>

</div>
</div>
</div>
</div>

 


    </main>
    