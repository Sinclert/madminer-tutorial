---
title: |-
  Setup the REANA / MLFlow
pagenum: 28
prev_page:
  url: /reana/parametrization.html
next_page:
  url: /reana/exec_remotely.html
suffix: .md
search: reana server mlflow tracking workflow client install instance cluster bash export ml cern local run workflows running need here url experiments host madminer institution case metrics create configure locally python interface user ch token access web address setup nyu username remote browser port images png sub runs deployed mlflowtrackinguri experiment name information below remotely easy package command submitting laptop submit type pip files environment not public example also bnl lab platform deploy greene research backend before set order reanaserverurl connection check following output version monitor ssh schematic machine projects results artifacts only file tmp docker internal describes software needed provides

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Setup the REANA / MLFlow</div>
</div>
    
<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The information below describes how to install and configure the software needed to run the workflow remotely or locally.</p>
<h2 id="Install-the-REANA-client">Install the REANA client<a class="anchor-link" href="#Install-the-REANA-client"> </a></h2><p>The <code>reana-client</code> is an easy-to-install python package that provides a command line interface (CLI) for submitting workflows to a REANA cluster. Normally, you would configure the workflow locally on your laptop or some interactive node on a cluster and then use the <code>reana-client</code> to submit the workflow to the REANA cluster. To install the <code>reana-client</code> simply type:</p>
<div class="highlight"><pre><span></span>pip3 install reana-client
</pre></div>
<p>The official documentation and the README files of these repositories recommend creating a Python virtual environment to install these packages. However, if your interaction with the project is going to be from a user perspective, this is not mandatory.</p>
<p>If you are running at CERN with lxplus, you can don't even need to install the client, you can just type <code>$ source /afs/cern.ch/user/r/reana/public/reana/bin/activate</code> as described in the <a href="http://docs.reana.io/getting-started/first-example/">first REANA example</a>.</p>
<h2 id="Get-a-Token-from-the-REANA-server">Get a Token from the REANA server<a class="anchor-link" href="#Get-a-Token-from-the-REANA-server"> </a></h2><p>You will need access to a REANA server instance. You can find your authentication <strong>token</strong> from the web interface for the REANA cluster. 
There is a REANA instance at CERN <a href="https://reana.cern.ch">https://reana.cern.ch</a>, but it requires a CERN IP address. There is also one running at BNL, which was used for the <a href="demo_video">demo video</a>. You can also contact the system administrators for your university or lab to ask if they can setup a REANA instance, or if you have credits on a public cloud computing platform it's fairly easy to deploy REANA there. For instance, we have setup a REANA instance on the <a href="https://www.nyu.edu/research/navigating-research-technology/nyu-greene.html">NYU Greene</a> cluster, which uses the SLURM backend to submit jobs.</p>
<h2 id="Configure-the-client">Configure the client<a class="anchor-link" href="#Configure-the-client"> </a></h2><p>Before submitting your workflows, you will  need to set some environment variables in order for the <code>reana-client</code> to be able to connect with a REANA server instance.</p>
<div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">REANA_ACCESS_TOKEN</span><span class="o">=</span>“&lt;your access token here&gt;”
<span class="nb">export</span> <span class="nv">REANA_SERVER_URL</span><span class="o">=</span>“&lt;the REANA instance URL here&gt;”
<span class="nb">export</span> <span class="nv">REANA_WORKON</span><span class="o">=</span>madminer-workflow
</pre></div>
<p>To determine if the connection is established check the following output</p>
<div class="highlight"><pre><span></span>reana-client ping
</pre></div>

<pre><code>REANA server: &lt;REANA_URL_SERVER&gt;
REANA server version: 0.7.1
REANA client version: 0.7.2
Authenticated as: &lt;username&gt; &lt;username@institution&gt;
Status: Connected</code></pre>
<h2 id="Local-monitoring-of-remote-workflows">Local monitoring of remote workflows<a class="anchor-link" href="#Local-monitoring-of-remote-workflows"> </a></h2><p>If we have access to a remote REANA server instance, it is more helpful to monitor the workflows and retrieve output files from the local browser than from the working directory at the cluster’s institution. Here are the steps to do it:</p>
<div class="highlight"><pre><span></span><span class="c1">#local terminal, ssh to the institution hosting the REANA server</span>
ssh -q -L &lt;port&gt;:&lt;REANA_SERVER_URL&gt;:&lt;port&gt; &lt;username&gt;@&lt;institution&gt;
<span class="c1">#if the previous command brings you to a bastion, go ahead and login to your workspace</span>
</pre></div>
<p>In the particular case of the Brookhaven National Lab, the REANA cluster URL is <code>https://kubmaster01.sdcc.bnl.gov:30443</code>.</p>
<p>You can check the progress of your workflow on <code>https://localhost:30443</code> using your local browser.</p>
<p><img src="../images/mm-reana-workflows.png" alt=""></p>
<h2 id="A-schematic-for-a-user-and-REANA-cluster">A schematic for a user and REANA cluster<a class="anchor-link" href="#A-schematic-for-a-user-and-REANA-cluster"> </a></h2><p>Below is a schematic showing your local machine (the smiley face) with the <code>reana-client</code> and local web browser monitor interacting with the remote REANA cluster.</p>
<p><img src="../images/reana-platform-20181202.png" alt=""></p>
<h1 id="Optional:-MLFlow-tracking-server">Optional: MLFlow tracking server<a class="anchor-link" href="#Optional:-MLFlow-tracking-server"> </a></h1><p><a href="https://mlflow.org">MLFlow</a> is a framework that offers developers a consistent way of (1) defining ML projects, (2) run parameterized experiments on those projects, and (3) track results, metrics and artifacts from run to run.</p>
<p><img src="../images/mlflow_screenshot.png" alt=""></p>
<p>MLFlow has been <strong>integrated to the ML sub-workflow</strong>, in order to provide the third capability: the tracking of results and metrics on consecutive (but different) runs. Therefore, the following information applies only to the ML sub-workflow leaving the physics sub-workflow unaffected.</p>
<p>If you want to make Machine Learning metrics accessible through a web interface, you will need a MLFlow tracking server <em>up and running</em>. This could be provided to you (usual case), or deployed by you at a network open address (such as the address <code>0.0.0.0</code> on your laptop).</p>
<p>To deploy your very own MLFlow tracking server:</p>
<div class="highlight"><pre><span></span><span class="c1"># Install the Python package</span>
pip3 install mlflow

<span class="c1"># Launch the tracking server</span>
mlflow server <span class="se">\ </span>                                                
    --host <span class="s2">&quot;0.0.0.0&quot;</span> <span class="se">\</span>
    --port <span class="m">5000</span> <span class="se">\</span>
    --workers <span class="m">2</span> <span class="se">\</span>
    --backend-store-uri <span class="s2">&quot;file:///tmp/mlflow/runs/metadata&quot;</span> <span class="se">\</span>
    --default-artifact-root <span class="s2">&quot;file:///tmp/mlflow/runs/artifacts&quot;</span>
</pre></div>
<h3 id="Connection-setup">Connection setup<a class="anchor-link" href="#Connection-setup"> </a></h3><p>Once you have a MLFlow tracking server instance <em>up and running</em>, you need to create the MLFlow <em>experiments</em> to which the workflow ML metrics will be associated to. To do it:</p>
<div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">MLFLOW_TRACKING_URI</span><span class="o">=</span>”&lt;the tracking server URL here&gt;”

mlflow experiments create --experiment-name <span class="s2">&quot;madminer-ml-sample&quot;</span>
mlflow experiments create --experiment-name <span class="s2">&quot;madminer-ml-train&quot;</span>
mlflow experiments create --experiment-name <span class="s2">&quot;madminer-ml-eval&quot;</span>
</pre></div>
<p>Now, you are ready to run the workflow with a properly configured MLFlow tracking server. Do not forget to set the tracking server URL before running the workflow.</p>
<p>In case the tracking server is deployed <strong>remotely</strong>:</p>
<div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">MLFLOW_TRACKING_URI</span><span class="o">=</span>”&lt;the tracking server URL here&gt;”
</pre></div>
<p>In case the tracking server is deployed <strong>locally</strong> in your computer:</p>
<div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">MLFLOW_TRACKING_URI</span><span class="o">=</span><span class="s2">&quot;http://host.docker.internal:5000&quot;</span>
<span class="nb">export</span> <span class="nv">PACKTIVITY_DOCKER_CMD_MOD</span><span class="o">=</span><span class="s2">&quot;--add-host host.docker.internal:host-gateway&quot;</span> <span class="c1"># Only if you are on linux</span>
</pre></div>

</div>
</div>
</div>
</div>

 


    </main>
    